{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import torch as th\n",
    "import torch as tn\n",
    "from torchtext import vocab\n",
    "import pickle as pl\n",
    "from Models.Transformer import Transformer\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "with open('data/English_encodings.pkl', 'rb') as f:\n",
    "    english_encodings,english_sentences,Paddings_en,Vocab_en = pl.load(f)\n",
    "with open('data/French_encodings.pkl', 'rb') as f:\n",
    "    french_encodings,french_sentences,Paddings_fr,Vocab_fr = pl.load(f)\n",
    "\n",
    "# Get the vocabulary size\n",
    "src_vocab_size = Vocab_fr.__len__()\n",
    "tgt_vocab_size = Vocab_en.__len__()\n",
    "src_padding_idx = Vocab_fr.__getitem__('<Pad>')\n",
    "tgt_padding_idx = Vocab_en.__getitem__('<Pad>')\n",
    "\n",
    "\n",
    "# Load Train,Vaildation and Test data\n",
    "with open('data/Train_data.pkl', 'rb') as f:\n",
    "    X_train,Y_train,src_padding_mask,tgt_padding_mask = pl.load(f)\n",
    "\n",
    "with open('data/Validation_data.pkl', 'rb') as f:\n",
    "    X_vali,Y_vali,src_padding_mask_vali = pl.load(f)\n",
    "\n",
    "with open('data/Test_data.pkl', 'rb') as f:\n",
    "    X_test,Y_test,src_padding_mask_test = pl.load(f)\n",
    "\n",
    "tgt_mask = th.triu(th.full((27, 27), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train(model, src_data, tgt_data, src_padding_mask, tgt_padding_mask, tgt_mask, optimizer, loss_fn, epochs, Model_Params=None):\n",
    "    \n",
    "    # Check if CUDA/mps is available\n",
    "    if tn.cuda.is_available():\n",
    "        device = tn.device(\"cuda\")\n",
    "    elif tn.backends.mps.is_available():\n",
    "        device = \"cpu\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    \n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Move the data to the device\n",
    "    src_data = src_data.to(device)\n",
    "    tgt_data = tgt_data.to(device)\n",
    "    src_padding_mask = src_padding_mask.to(device)\n",
    "    tgt_padding_mask = tgt_padding_mask.to(device)\n",
    "    tgt_mask = tgt_mask.to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    # Initialize the loss\n",
    "    loss_train = []\n",
    "    loss_vali = []\n",
    "    \n",
    "    n_batches,batch_size,_ = src_data.shape\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize the loss\n",
    "        epoch_loss = 0\n",
    "        epoch_loss_vali = 0\n",
    "        # Train the model\n",
    "        for src_batch,tgt_batch,src_pad,tgt_pad in zip(src_data,tgt_data,src_padding_mask,tgt_padding_mask):\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Batch loss\n",
    "            loss = 0\n",
    "\n",
    "            # Go trough each batch\n",
    "            for i in range(batch_size):\n",
    "                out = model(src_batch[i],tgt_batch[i],\n",
    "                        tgt_mask = tgt_mask,\n",
    "                        src_padding_mask = src_pad[i],\n",
    "                        tgt_padding_mask = tgt_pad[i]\n",
    "                        )\n",
    "\n",
    "                loss += loss_fn(out,tgt_batch[i])\n",
    "            \n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add the loss\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} Loss: {epoch_loss/(n_batches*batch_size)}')\n",
    "\n",
    "        # Validation loss\n",
    "        loss_train.append(epoch_loss/(n_batches*batch_size))\n",
    "    \n",
    "    return loss_train,model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.6093930823802948\n",
      "Epoch 2/10 Loss: 0.08980004706382752\n",
      "Epoch 3/10 Loss: 0.024470868477225304\n",
      "Epoch 4/10 Loss: 0.01101403956860304\n",
      "Epoch 5/10 Loss: 0.006339043017476797\n",
      "Epoch 6/10 Loss: 0.0040952004700899125\n",
      "Epoch 7/10 Loss: 0.0025887869469821455\n",
      "Epoch 8/10 Loss: 0.001811503766477108\n",
      "Epoch 9/10 Loss: 0.0012825682822614909\n",
      "Epoch 10/10 Loss: 0.0011480199214071035\n"
     ]
    }
   ],
   "source": [
    "# Intialize the model with set hyperparameters\n",
    "T = 27\n",
    "d_model = 512 # Dimension of the model (Embedding size)\n",
    "d_ff = 2048 # Dimension of the feedforward network model in transformer\n",
    "nhead = 8 # Number of heads in the multiheadattention models\n",
    "dk = d_model//nhead\n",
    "dv = d_model//nhead\n",
    "num_layers = 6\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "Model = Transformer(\n",
    "    T = T,\n",
    "    d_model = d_model,\n",
    "    nhead = nhead,\n",
    "    d_ff = d_ff,\n",
    "    dk = dk,\n",
    "    dv = dv,\n",
    "    num_layers = num_layers,\n",
    "    src_vocab_size = src_vocab_size,\n",
    "    tgt_vocab_size = tgt_vocab_size,\n",
    "    src_padding_idx = src_padding_idx,\n",
    "    tgt_padding_idx = tgt_padding_idx,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "loss_fn = tn.nn.CrossEntropyLoss()\n",
    "optimizer = tn.optim.Adam(Model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "loss_train,Model = train(Model, X_train, Y_train, src_padding_mask, tgt_padding_mask, tgt_mask, optimizer, loss_fn, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn.save(Model.state_dict(), \"Models/Transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X,print_sentence = True):\n",
    "    Prediction = th.zeros(27,dtype=th.int32)\n",
    "    Prediction[:] = Vocab_en.__getitem__('<Pad>')\n",
    "    Prediction_mask = th.zeros((27,128))\n",
    "\n",
    "    Prediction[0] = Vocab_en.__getitem__('<Start>')\n",
    "    Prediction_mask[0] = 1\n",
    "\n",
    "    src_mask = tn.ones((27,128))\n",
    "    src_mask[-(X == Vocab_fr.__getitem__('<Pad>')).sum():] = 0\n",
    "\n",
    "    for i in range(1,27):\n",
    "        out = Model(X_test[0],Prediction,src_padding_mask = src_mask,tgt_mask=tgt_mask,tgt_padding_mask = Prediction_mask)\n",
    "        Prediction[i] = out.argmax(1)[i]\n",
    "        Prediction_mask[i] = 1\n",
    "\n",
    "    \n",
    "    if print_sentence:\n",
    "        Senctence = \"\"\n",
    "        for word in Vocab_en.lookup_tokens(Prediction.tolist()):\n",
    "            Senctence += \" \" + word\n",
    "\n",
    "        print(Senctence)\n",
    "\n",
    "    \n",
    "    return Prediction,src_mask\n",
    "\n",
    "def Predict_loss(X,Y,print_sentence = True):\n",
    "\n",
    "    Prediction = th.zeros(27,dtype=th.int32)\n",
    "    Prediction[:] = Vocab_en.__getitem__('<Pad>')\n",
    "    \n",
    "    Prediction_mask = th.zeros((27,d_model))\n",
    "\n",
    "    Prediction_vectors = th.zeros((27,tgt_vocab_size))\n",
    "    Prediction_vectors[0][204] = 1\n",
    "\n",
    "\n",
    "    Prediction[0] = Vocab_en.__getitem__('<Start>')\n",
    "    Prediction_mask[0] = 1\n",
    "\n",
    "    src_mask = tn.ones((27,d_model))\n",
    "    src_mask[-(X == Vocab_fr.__getitem__('<Pad>')).sum():] = 0\n",
    "\n",
    "    for i in range(1,27):\n",
    "        out = Model(X,Prediction,src_padding_mask = src_mask,tgt_mask=tgt_mask,tgt_padding_mask = Prediction_mask)\n",
    "        Prediction[i] = out.argmax(1)[i]\n",
    "        Prediction_vectors[i] = out[i]\n",
    "        Prediction_mask[i] = 1\n",
    "\n",
    "    \n",
    "    if print_sentence:\n",
    "        Senctence_pred = \"\"\n",
    "        for word in Vocab_en.lookup_tokens(Prediction.tolist()):\n",
    "            Senctence_pred += \" \" + word\n",
    "\n",
    "        print(\"Predicted Senctence:\")\n",
    "        print(Senctence_pred)\n",
    "        print(\"\")\n",
    "        Senctence_true = \"\"\n",
    "        for word in Vocab_en.lookup_tokens(Y.tolist()):\n",
    "            Senctence_true += \" \" + word\n",
    "        print(\"True Senctence:\")\n",
    "        print(Senctence_true)\n",
    "\n",
    "    loss = loss_fn(Prediction_vectors,Y)\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Senctence:\n",
      " <Start> her least favorite fruit is the banana , but your least favorite is the lime . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> her least favorite fruit is the banana , but your least favorite is the lime . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 0.2303076982498169\n",
      "Predicted Senctence:\n",
      " <Start> the united states is pleasant may may may , and it is quiet warm august <Pad> <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> the united states is nice during may , and it is quiet in august . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 2.5806100368499756\n",
      "Predicted Senctence:\n",
      " <Start> california is sometimes warm during june , but it is sometimes snowy fall autumn <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> california is sometimes hot during june , but it is usually snowy in fall . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 0.6739318370819092\n",
      "Predicted Senctence:\n",
      " <Start> the peach is their least favorite fruit , but the apple is our least favorite . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> the peach is their least favorite fruit , but the apple is our least favorite . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 0.21037045121192932\n",
      "Predicted Senctence:\n",
      " <Start> california is usually dry during september , and it is sometimes in december . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> california is usually dry during november , but it is usually chilly in may . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 1.9069974422454834\n"
     ]
    }
   ],
   "source": [
    "Model.to(\"cpu\")\n",
    "for i in range(5):\n",
    "    Predict_loss(X_test[i],Y_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2161e111f783a6322a6ae262a47844d9386d7dfb61a436620c434d93864cb0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
