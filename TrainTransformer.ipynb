{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magnusharder/Documents/UNI-DTU/6. Semester/Arkitektur - Special Course/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import copy\n",
    "import torch as th\n",
    "import torch as tn\n",
    "from torchtext import vocab\n",
    "import pickle as pl\n",
    "from Models.Transformer import Transformer\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "with open('data/English_encodings.pkl', 'rb') as f:\n",
    "    english_encodings,english_sentences,Paddings_en,Vocab_en = pl.load(f)\n",
    "with open('data/French_encodings.pkl', 'rb') as f:\n",
    "    french_encodings,french_sentences,Paddings_fr,Vocab_fr = pl.load(f)\n",
    "\n",
    "# Get the vocabulary size\n",
    "src_vocab_size = Vocab_fr.__len__()\n",
    "tgt_vocab_size = Vocab_en.__len__()\n",
    "src_padding_idx = Vocab_fr.__getitem__('<Pad>')\n",
    "tgt_padding_idx = Vocab_en.__getitem__('<Pad>')\n",
    "\n",
    "\n",
    "# Load Train,Vaildation and Test data\n",
    "with open('data/Train_data.pkl', 'rb') as f:\n",
    "    X_train,Y_train,src_padding_mask,tgt_padding_mask = pl.load(f)\n",
    "\n",
    "with open('data/Validation_data.pkl', 'rb') as f:\n",
    "    X_vali,Y_vali,src_padding_mask_vali = pl.load(f)\n",
    "\n",
    "with open('data/Test_data.pkl', 'rb') as f:\n",
    "    X_test,Y_test,src_padding_mask_test = pl.load(f)\n",
    "\n",
    "tgt_mask = th.triu(th.full((27, 27), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train the model\n",
    "def train(model, src_data, tgt_data, src_padding_mask, tgt_padding_mask, tgt_mask, optimizer, loss_fn, epochs):\n",
    "    \n",
    "    # Check if CUDA/mps is available\n",
    "    if tn.cuda.is_available():\n",
    "        device = tn.device(\"cpu\")\n",
    "    elif tn.backends.mps.is_available():\n",
    "        device = \"cpu\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    \n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Move the data to the device\n",
    "    src_data = src_data.to(device)\n",
    "    tgt_data = tgt_data.to(device)\n",
    "    src_padding_mask = src_padding_mask.to(device)\n",
    "    tgt_padding_mask = tgt_padding_mask.to(device)\n",
    "    tgt_mask = tgt_mask.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Initialize the loss\n",
    "    loss_train = []\n",
    "    \n",
    "    n_batches,batch_size,_ = src_data.shape\n",
    "\n",
    "   \n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize the loss\n",
    "        epoch_loss = 0\n",
    "        # Train the model\n",
    "        \n",
    "        for src_batch,tgt_batch,src_pad,tgt_pad in zip(src_data,tgt_data,src_padding_mask,tgt_padding_mask):\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Batch loss\n",
    "            loss = 0\n",
    "\n",
    "            # Go trough each batch\n",
    "            for i in range(batch_size):\n",
    "                out = model(src_batch[i],tgt_batch[i],\n",
    "                        tgt_mask = tgt_mask,\n",
    "                        src_padding_mask = src_pad[i],\n",
    "                        tgt_padding_mask = tgt_pad[i]\n",
    "                        )\n",
    "\n",
    "                loss += loss_fn(out,tgt_batch[i])\n",
    "\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add the loss\n",
    "            epoch_loss += loss.item()\n",
    "            loss_train.append(loss.item())\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} Loss: {epoch_loss/(n_batches*batch_size)}')\n",
    "\n",
    "    \n",
    "    return loss_train, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 Loss: 0.027768142700195314\n"
     ]
    }
   ],
   "source": [
    "# Intialize the model with set hyperparameters\n",
    "T = 27\n",
    "d_model = 512 # Dimension of the model (Embedding size)\n",
    "d_ff = 2048 # Dimension of the feedforward network model in transformer\n",
    "nhead = 8 # Number of heads in the multiheadattention models\n",
    "dk = d_model//nhead\n",
    "dv = d_model//nhead\n",
    "num_layers = 6\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "Model = Transformer(\n",
    "    T = T,\n",
    "    d_model = d_model,\n",
    "    nhead = nhead,\n",
    "    d_ff = d_ff,\n",
    "    dk = dk,\n",
    "    dv = dv,\n",
    "    num_layers = num_layers,\n",
    "    src_vocab_size = src_vocab_size,\n",
    "    tgt_vocab_size = tgt_vocab_size,\n",
    "    src_padding_idx = src_padding_idx,\n",
    "    tgt_padding_idx = tgt_padding_idx,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "loss_fn = tn.nn.CrossEntropyLoss()\n",
    "optimizer = tn.optim.Adam(Model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "loss_train,vali_losses, Model = train(Model, X_train, Y_train, src_padding_mask, tgt_padding_mask, tgt_mask, optimizer, loss_fn, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn.save(Model.state_dict(), \"Models/Transformer.pt\")\n",
    "\n",
    "\n",
    "\n",
    "with open('Models/TransformerLoss.pkl', 'wb') as f:\n",
    "    pl.dump([loss_train, vali_losses] ,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X,print_sentence = True):\n",
    "    Prediction = th.zeros(27,dtype=th.int32)\n",
    "    Prediction[:] = Vocab_en.__getitem__('<Pad>')\n",
    "    Prediction_mask = th.zeros((27,128))\n",
    "\n",
    "    Prediction[0] = Vocab_en.__getitem__('<Start>')\n",
    "    Prediction_mask[0] = 1\n",
    "\n",
    "    src_mask = tn.ones((27,128))\n",
    "    src_mask[-(X == Vocab_fr.__getitem__('<Pad>')).sum():] = 0\n",
    "\n",
    "    for i in range(1,27):\n",
    "        out = Model(X_test[0],Prediction,src_padding_mask = src_mask,tgt_mask=tgt_mask,tgt_padding_mask = Prediction_mask)\n",
    "        Prediction[i] = out.argmax(1)[i]\n",
    "        Prediction_mask[i] = 1\n",
    "\n",
    "    \n",
    "    if print_sentence:\n",
    "        Senctence = \"\"\n",
    "        for word in Vocab_en.lookup_tokens(Prediction.tolist()):\n",
    "            Senctence += \" \" + word\n",
    "\n",
    "        print(Senctence)\n",
    "\n",
    "    \n",
    "    return Prediction,src_mask\n",
    "\n",
    "def Predict_loss(X,Y,print_sentence = True):\n",
    "\n",
    "    Prediction = th.zeros(27,dtype=th.int32)\n",
    "    Prediction[:] = Vocab_en.__getitem__('<Pad>')\n",
    "    \n",
    "    Prediction_mask = th.zeros((27,d_model))\n",
    "\n",
    "    Prediction_vectors = th.zeros((27,tgt_vocab_size))\n",
    "    Prediction_vectors[0][204] = 1\n",
    "\n",
    "\n",
    "    Prediction[0] = Vocab_en.__getitem__('<Start>')\n",
    "    Prediction_mask[0] = 1\n",
    "\n",
    "    src_mask = tn.ones((27,d_model))\n",
    "    src_mask[-(X == Vocab_fr.__getitem__('<Pad>')).sum():] = 0\n",
    "\n",
    "    for i in range(1,27):\n",
    "        out = Model(X,Prediction,src_padding_mask = src_mask,tgt_mask=tgt_mask,tgt_padding_mask = Prediction_mask)\n",
    "        Prediction[i] = out.argmax(1)[i]\n",
    "        Prediction_vectors[i] = out[i]\n",
    "        Prediction_mask[i] = 1\n",
    "\n",
    "    \n",
    "    if print_sentence:\n",
    "        Senctence_pred = \"\"\n",
    "        for word in Vocab_en.lookup_tokens(Prediction.tolist()):\n",
    "            Senctence_pred += \" \" + word\n",
    "\n",
    "        print(\"Predicted Senctence:\")\n",
    "        print(Senctence_pred)\n",
    "        print(\"\")\n",
    "        Senctence_true = \"\"\n",
    "        for word in Vocab_en.lookup_tokens(Y.tolist()):\n",
    "            Senctence_true += \" \" + word\n",
    "        print(\"True Senctence:\")\n",
    "        print(Senctence_true)\n",
    "\n",
    "    loss = loss_fn(Prediction_vectors,Y)\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Senctence:\n",
      " <Start> her least favorite fruit is the banana , but your least favorite is the lime . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> her least favorite fruit is the banana , but your least favorite is the lime . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 0.2475370168685913\n",
      "Predicted Senctence:\n",
      " <Start> the united states is warm may may may and it is is quiet in august . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> the united states is nice during may , and it is quiet in august . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 2.326324224472046\n",
      "Predicted Senctence:\n",
      " <Start> california is sometimes warm during june , but it is busy snowy autumn autumn . <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> california is sometimes hot during june , but it is usually snowy in fall . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 0.7047181725502014\n",
      "Predicted Senctence:\n",
      " <Start> the peach is their favorite fruit fruit , but the apple is our least favorite . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> the peach is their least favorite fruit , but the apple is our least favorite . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 0.3412400782108307\n",
      "Predicted Senctence:\n",
      " <Start> california is usually dry during may but november is is busy busy autumn <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "\n",
      "True Senctence:\n",
      " <Start> california is usually dry during november , but it is usually chilly in may . <End> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad> <Pad>\n",
      "Loss: 1.7566590309143066\n"
     ]
    }
   ],
   "source": [
    "Model.to(\"cpu\")\n",
    "for i in range(5):\n",
    "    Predict_loss(X_test[i],Y_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "554043c00383563873f7de553f5ef220995ac86d49372a9e11c31629c859d6a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
