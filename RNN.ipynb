{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torchtext import vocab\n",
    "import pickle as pl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Import model\n",
    "from Models.RNN import GRUNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "with open('data/English_encodings.pkl', 'rb') as f:\n",
    "    english_encodings,english_sentences,Paddings_en,Vocab_en = pl.load(f)\n",
    "with open('data/French_encodings.pkl', 'rb') as f:\n",
    "    french_encodings,french_sentences,Paddings_fr,Vocab_fr = pl.load(f)\n",
    "\n",
    "# Get the vocabulary size\n",
    "src_vocab_size = Vocab_fr.__len__()\n",
    "tgt_vocab_size = Vocab_en.__len__()\n",
    "src_padding_idx = Vocab_fr.__getitem__('<Pad>')\n",
    "tgt_padding_idx = Vocab_en.__getitem__('<Pad>')\n",
    "\n",
    "\n",
    "# Load Train,Vaildation and Test data\n",
    "with open('data/Train_data.pkl', 'rb') as f:\n",
    "    X_train,Y_train,src_padding_mask,tgt_padding_mask = pl.load(f)\n",
    "\n",
    "with open('data/Validation_data.pkl', 'rb') as f:\n",
    "    X_vali,Y_vali,src_padding_mask_vali = pl.load(f)\n",
    "\n",
    "with open('data/Test_data.pkl', 'rb') as f:\n",
    "    X_test,Y_test,src_padding_mask_test = pl.load(f)\n",
    "\n",
    "tgt_mask = th.triu(th.full((27, 27), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 10000\n",
    "batch_size = 50\n",
    "# Define Training Function\n",
    "def train(model, optimizer, loss_fn, n_epochs, n_batches, X_train, Y_train, X_vali, Y_vali):\n",
    "\n",
    "\n",
    "     # Check if CUDA/mps is available\n",
    "    if th.cuda.is_available():\n",
    "        device = th.device(\"cuda\")\n",
    "    elif th.backends.mps.is_available():\n",
    "        device = \"cpu\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    \n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Predict token\n",
    "    predict_token = th.tensor([Vocab_fr.__getitem__('<Pad>')],dtype=th.int32)\n",
    "\n",
    "    # Move the data to the device\n",
    "    X_train = X_train.to(device)\n",
    "    Y_train = Y_train.to(device)\n",
    "    predict_token = predict_token.to(device)\n",
    "\n",
    "    loss_batches = []\n",
    "    # Train for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_epoch = 0\n",
    "        for batch in range(n_batches):\n",
    "            model.to(device)\n",
    "\n",
    "            # Get the data\n",
    "\n",
    "            X_batch = X_train[batch]\n",
    "            Y_batch = Y_train[batch]\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch,predict_token,device)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = 0 \n",
    "            for sample in range(batch_size):\n",
    "                loss += loss_fn(y_pred[sample], Y_batch[sample])\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # Print the loss\n",
    "            loss_batches.append(loss.item())\n",
    "            loss_epoch += loss.item()\n",
    "\n",
    "        print('Epoch: %d, Batch: %d, Loss: %f' % (epoch, batch, loss_epoch/n_train))\n",
    "    return loss_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "dim_input = d_model\n",
    "dim_output = d_model\n",
    "dim_recurrent = d_model\n",
    "num_sequence = 27\n",
    "output = tgt_vocab_size\n",
    "src_padding_idx = Vocab_en.__getitem__('<Pad>')\n",
    "\n",
    "Model = GRUNet(dim_input, dim_recurrent, num_sequence, src_padding_idx, tgt_padding_idx, src_vocab_size,tgt_vocab_size)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer LSTM\n",
    "optimizer = th.optim.Adam(Model.parameters(), lr=0.0001)\n",
    "\n",
    "#define the number of epochs\n",
    "n_epochs = 2\n",
    "batch_size = 50\n",
    "n_train = 10000\n",
    "\n",
    "# Define the number of batches\n",
    "n_batches = 2\n",
    "\n",
    "\n",
    "loss_batches = train(Model, optimizer, loss_fn, n_epochs, n_batches, X_train, Y_train, X_vali, Y_vali)\n",
    "\n",
    "th.save(Model.state_dict(), \"Models/RNN.pt\")\n",
    "\n",
    "with open('Models/RnnLoss.pkl', 'wb') as f:\n",
    "    pl.dump(loss_batches,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   6,   0,   0,   1,   5,   1,   1,   1,   4,   0, 205, 205,   3,\n",
       "        205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.to(\"cpu\")\n",
    "predict_token = th.tensor([Vocab_en.__getitem__('<Start>')],dtype = th.int32)\n",
    "\n",
    "predict_token_batch = th.zeros((n_batches,1),dtype=th.int32)\n",
    "predict_token_batch[:] = Vocab_fr.__getitem__('<Pad>')\n",
    "\n",
    "\n",
    "out = Model(X_train[0],predict_token)\n",
    "out[0].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Dec  7 2022, 10:02:13) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "554043c00383563873f7de553f5ef220995ac86d49372a9e11c31629c859d6a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
